{"cells":[{"cell_type":"code","source":["# IMporting SQL libraries\nfrom pyspark.sql.types import *\n# from pyspark.sql.functions import * \nfrom pyspark.sql.functions import sum as _sum"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["# Reading files from createed table\ncsv = spark.sql('select * from azureData4')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["csv.createTempView('mytable3')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["csv.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: [&#39;processed_text&#39;, &#39;y&#39;]</div>"]}}],"execution_count":4},{"cell_type":"code","source":["spark.sql('select count(*) from mytable3').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+\ncount(1)|\n+--------+\n   33183|\n+--------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# IMporting libraries\nfrom pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\nfrom pyspark.ml.classification import LogisticRegression\n\n# regular expression tokenizer\nregexTokenizer = RegexTokenizer(inputCol=\"processed_text\", outputCol=\"words\", pattern=\"\\\\s+\")\n\n# stop words\nadd_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"can\", # standard stop words\n     \"#keithlamontscott\",\"#charlotteprotest\",\"#charlotteriots\",\"#keithscott\"] # keywords used to pull data)\nstopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords)\n\n# bag of words count\n# Here we created bag of words as 10000 beecause more than that will take hours to compute and sometimes fails to.\ncountVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\", vocabSize=10000, minDF=5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["# Creating pipeline of basic data cleaning and creating dataset with all features.\nfrom pyspark.ml import Pipeline\n\npipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors])\n\n# Fit the pipeline to training documents.\npipelineFit = pipeline.fit(csv)\n# Transform dataset with new pipelined features.\ndataset = pipelineFit.transform(csv)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["dataset.dtypes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: [(&#39;processed_text&#39;, &#39;string&#39;),\n (&#39;y&#39;, &#39;int&#39;),\n (&#39;words&#39;, &#39;array&lt;string&gt;&#39;),\n (&#39;filtered&#39;, &#39;array&lt;string&gt;&#39;),\n (&#39;features&#39;, &#39;vector&#39;)]</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Implementing logistic regression"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 23269\nTest Dataset Count: 9914\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["trainingData.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+---+--------------------+--------------------+--------------------+\n      processed_text|  y|               words|            filtered|            features|\n+--------------------+---+--------------------+--------------------+--------------------+\n1 deadline compli...|  0|[1, deadline, com...|[1, deadline, com...|(10000,[2,3,4,5,8...|\n1 introduction tr...|  1|[1, introduction,...|[1, introduction,...|(10000,[0,1,2,5,6...|\n1,4-glcnac- ␤ pre...|  1|[1,4-glcnac-, ␤, ...|[1,4-glcnac-, ␤, ...|(10000,[0,1,2,3,4...|\n10 case 23.81 urt...|  0|[10, case, 23.81,...|[10, case, 23.81,...|(10000,[1,2,3,4,5...|\n114 catalytic hyd...|  1|[114, catalytic, ...|[114, catalytic, ...|(10000,[0,1,2,5,6...|\n120 year pass wal...|  1|[120, year, pass,...|[120, year, pass,...|(10000,[0,1,2,3,4...|\n17 160 type modif...|  1|[17, 160, type, m...|[17, 160, type, m...|(10000,[0,2,3,4,6...|\n170 million chron...|  0|[170, million, ch...|[170, million, ch...|(10000,[0,1,2,5,7...|\n170 million peopl...|  1|[170, million, pe...|[170, million, pe...|(10000,[0,1,2,5,6...|\n1918 world war wi...|  0|[1918, world, war...|[1918, world, war...|(10000,[1,2,3,4,5...|\n1959 richard feyn...|  1|[1959, richard, f...|[1959, richard, f...|(10000,[0,1,2,3,4...|\n1980 average new ...|  0|[1980, average, n...|[1980, average, n...|(10000,[1,2,5,6,7...|\n1980s world healt...|  0|[1980s, world, he...|[1980s, world, he...|(10000,[1,2,5,6,7...|\n1995 haemophilus ...|  1|[1995, haemophilu...|[1995, haemophilu...|(10000,[0,1,2,7,8...|\n1997 highly patho...|  1|[1997, highly, pa...|[1997, highly, pa...|(10000,[0,1,2,3,4...|\n1997 study report...|  1|[1997, study, rep...|[1997, study, rep...|(10000,[0,1,2,3,4...|\n1998 world health...|  0|[1998, world, hea...|[1998, world, hea...|(10000,[2,5,7,8,9...|\n20 year alphaviru...|  1|[20, year, alphav...|[20, year, alphav...|(10000,[0,1,2,3,4...|\n200 different typ...|  1|[200, different, ...|[200, different, ...|(10000,[0,1,2,3,4...|\n2000-year medicin...|  1|[2000-year, medic...|[2000-year, medic...|(10000,[0,1,2,3,4...|\n+--------------------+---+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["trainingData.dtypes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[145]: [(&#39;processed_text&#39;, &#39;string&#39;),\n (&#39;y&#39;, &#39;int&#39;),\n (&#39;words&#39;, &#39;array&lt;string&gt;&#39;),\n (&#39;filtered&#39;, &#39;array&lt;string&gt;&#39;),\n (&#39;features&#39;, &#39;vector&#39;)]</div>"]}}],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n# Build the model\nlr = LogisticRegression(labelCol='y', maxIter=20, regParam=0.3, elasticNetParam=0, family = \"binomial\")\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["trainingSummary = lrModel.summary"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nobjectiveHistory = trainingSummary.objectiveHistory\nplt.plot(objectiveHistory)\nplt.ylabel('Objective Function')\nplt.xlabel('Iteration')\nplt.show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">areaUnderROC: 0.9979946234942196\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport numpy as np\n\nbeta = np.sort(lrModel.coefficients)\n\nplt.plot(beta)\nplt.ylabel('Beta Coefficients')\nplt.show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["predictions = lrModel.transform(testData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["from pyspark.sql.functions import col\nsee = predictions.select('y', col('y').alias('label'), 'rawPrediction')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":19},{"cell_type":"code","source":["see.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+--------------------+\n  y|label|       rawPrediction|\n+---+-----+--------------------+\n  0|    0|[5.85770883288753...|\n  1|    1|[-3.7477454111755...|\n  1|    1|[-5.2221739289534...|\n  1|    1|[-4.1522020226677...|\n  1|    1|[-0.9887836907868...|\n  1|    1|[-1.9845441788294...|\n  1|    1|[-0.5578657853123...|\n  0|    0|[1.39997977579923...|\n  1|    1|[-6.2685294033022...|\n  1|    1|[-2.6162621398216...|\n  0|    0|[7.99472341814452...|\n  1|    1|[-4.0581854305074...|\n  0|    0|[4.25756155042867...|\n  0|    0|[6.77162591263091...|\n  1|    1|[-4.4712351957883...|\n  1|    1|[-2.9864624971901...|\n  0|    0|[4.22158594445307...|\n  0|    0|[2.99727677277623...|\n  1|    1|[-4.3020059850553...|\n  1|    1|[-4.3119701313827...|\n+---+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(see, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test: Area Under ROC: 0.9949234529734854\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["We are using decision tree classifier"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 23269\nTest Dataset Count: 9914\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"y\", featuresCol=\"features\", maxDepth=3)\n# Only for cli\n# dt = DecisionTreeClassifier(labelCol=\"y\", featuresCol=\"features\")\n# Train model with Training Data\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["# Evaluate model\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\npredictions = dtModel.transform(testData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["predictions.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+---+--------------------+--------------------+--------------------+--------------+--------------------+----------+\n      processed_text|  y|               words|            filtered|            features| rawPrediction|         probability|prediction|\n+--------------------+---+--------------------+--------------------+--------------------+--------------+--------------------+----------+\n100,000 patient a...|  0|[100,000, patient...|[100,000, patient...|(10000,[2,3,4,7,8...|[7693.0,848.0]|[0.90071420208406...|       0.0|\n14 species canadi...|  1|[14, species, can...|[14, species, can...|(10000,[1,2,5,7,8...| [535.0,712.0]|[0.42902967121090...|       1.0|\n14.69 60.02 propo...|  1|[14.69, 60.02, pr...|[14.69, 60.02, pr...|(10000,[1,2,5,6,7...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n15 year ago opden...|  1|[15, year, ago, o...|[15, year, ago, o...|(10000,[0,1,2,6,7...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n1970s tomisaku ka...|  1|[1970s, tomisaku,...|[1970s, tomisaku,...|(10000,[0,2,3,4,5...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n1990 computer use...|  1|[1990, computer, ...|[1990, computer, ...|(10000,[0,2,6,7,8...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n1992 laboratory p...|  1|[1992, laboratory...|[1992, laboratory...|(10000,[0,1,2,5,6...| [185.0,564.0]|[0.24699599465954...|       1.0|\n1995 ﻿1 pilot iss...|  0|[1995, ﻿1, pilot,...|[1995, ﻿1, pilot,...|(10000,[3,4,5,8,9...|[7693.0,848.0]|[0.90071420208406...|       0.0|\n2 billion people ...|  1|[2, billion, peop...|[2, billion, peop...|(10000,[0,1,2,3,4...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n2 million people ...|  1|[2, million, peop...|[2, million, peop...|(10000,[0,1,2,5,7...| [535.0,712.0]|[0.42902967121090...|       1.0|\n2003 2 million ca...|  0|[2003, 2, million...|[2003, 2, million...|(10000,[1,2,5,7,8...|[7693.0,848.0]|[0.90071420208406...|       0.0|\n2003 coronavirus ...|  1|[2003, coronaviru...|[2003, coronaviru...|(10000,[0,1,2,3,4...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n2003 hong kong pr...|  0|[2003, hong, kong...|[2003, hong, kong...|(10000,[2,3,4,7,8...|[7693.0,848.0]|[0.90071420208406...|       0.0|\n2003 world strike...|  0|[2003, world, str...|[2003, world, str...|(10000,[1,2,7,8,9...|[7693.0,848.0]|[0.90071420208406...|       0.0|\n2007 hiv-1 human ...|  1|[2007, hiv-1, hum...|[2007, hiv-1, hum...|(10000,[0,1,2,3,4...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n2008 field experi...|  1|[2008, field, exp...|[2008, field, exp...|(10000,[1,2,3,4,5...| [535.0,712.0]|[0.42902967121090...|       1.0|\n2009 h1n1 influen...|  0|[2009, h1n1, infl...|[2009, h1n1, infl...|(10000,[0,1,2,3,4...| [889.0,385.0]|[0.69780219780219...|       0.0|\n2009 infection no...|  0|[2009, infection,...|[2009, infection,...|(10000,[0,1,2,5,7...|[7693.0,848.0]|[0.90071420208406...|       0.0|\n2009 pandemic inf...|  1|[2009, pandemic, ...|[2009, pandemic, ...|(10000,[0,1,2,3,4...|[748.0,9253.0]|[0.07479252074792...|       1.0|\n2010 increase num...|  1|[2010, increase, ...|[2010, increase, ...|(10000,[0,1,2,5,6...| [185.0,564.0]|[0.24699599465954...|       1.0|\n+--------------------+---+--------------------+--------------------+--------------------+--------------+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["from pyspark.sql.functions import col\nsee = predictions.select('y', col('y').alias('label'), 'rawPrediction')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["see.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+--------------+\n  y|label| rawPrediction|\n+---+-----+--------------+\n  0|    0|[7693.0,848.0]|\n  1|    1| [535.0,712.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1| [185.0,564.0]|\n  0|    0|[7693.0,848.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1| [535.0,712.0]|\n  0|    0|[7693.0,848.0]|\n  1|    1|[748.0,9253.0]|\n  0|    0|[7693.0,848.0]|\n  0|    0|[7693.0,848.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1| [535.0,712.0]|\n  0|    0| [889.0,385.0]|\n  0|    0|[7693.0,848.0]|\n  1|    1|[748.0,9253.0]|\n  1|    1| [185.0,564.0]|\n+---+-----+--------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(see, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test: Area Under ROC: 0.8246139516794767\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["print (\"numNodes = \", dtModel.numNodes)\nprint (\"depth = \", dtModel.depth)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">numNodes =  13\ndepth =  3\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["# Implementing random forest classifier."],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 23269\nTest Dataset Count: 9914\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["trainingData.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+---+--------------------+--------------------+--------------------+\n      processed_text|  y|               words|            filtered|            features|\n+--------------------+---+--------------------+--------------------+--------------------+\n1 deadline compli...|  0|[1, deadline, com...|[1, deadline, com...|(10000,[2,3,4,5,8...|\n1 introduction tr...|  1|[1, introduction,...|[1, introduction,...|(10000,[0,1,2,5,6...|\n1,4-glcnac- ␤ pre...|  1|[1,4-glcnac-, ␤, ...|[1,4-glcnac-, ␤, ...|(10000,[0,1,2,3,4...|\n10 case 23.81 urt...|  0|[10, case, 23.81,...|[10, case, 23.81,...|(10000,[1,2,3,4,5...|\n114 catalytic hyd...|  1|[114, catalytic, ...|[114, catalytic, ...|(10000,[0,1,2,5,6...|\n120 year pass wal...|  1|[120, year, pass,...|[120, year, pass,...|(10000,[0,1,2,3,4...|\n17 160 type modif...|  1|[17, 160, type, m...|[17, 160, type, m...|(10000,[0,2,3,4,6...|\n170 million chron...|  0|[170, million, ch...|[170, million, ch...|(10000,[0,1,2,5,7...|\n170 million peopl...|  1|[170, million, pe...|[170, million, pe...|(10000,[0,1,2,5,6...|\n1918 world war wi...|  0|[1918, world, war...|[1918, world, war...|(10000,[1,2,3,4,5...|\n1959 richard feyn...|  1|[1959, richard, f...|[1959, richard, f...|(10000,[0,1,2,3,4...|\n1980 average new ...|  0|[1980, average, n...|[1980, average, n...|(10000,[1,2,5,6,7...|\n1980s world healt...|  0|[1980s, world, he...|[1980s, world, he...|(10000,[1,2,5,6,7...|\n1995 haemophilus ...|  1|[1995, haemophilu...|[1995, haemophilu...|(10000,[0,1,2,7,8...|\n1997 highly patho...|  1|[1997, highly, pa...|[1997, highly, pa...|(10000,[0,1,2,3,4...|\n1997 study report...|  1|[1997, study, rep...|[1997, study, rep...|(10000,[0,1,2,3,4...|\n1998 world health...|  0|[1998, world, hea...|[1998, world, hea...|(10000,[2,5,7,8,9...|\n20 year alphaviru...|  1|[20, year, alphav...|[20, year, alphav...|(10000,[0,1,2,3,4...|\n200 different typ...|  1|[200, different, ...|[200, different, ...|(10000,[0,1,2,3,4...|\n2000-year medicin...|  1|[2000-year, medic...|[2000-year, medic...|(10000,[0,1,2,3,4...|\n+--------------------+---+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":33},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"y\", \\\n                            featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["predictions = rfModel.transform(testData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["predictions.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n      processed_text|  y|               words|            filtered|            features|       rawPrediction|         probability|prediction|\n+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n100,000 patient a...|  0|[100,000, patient...|[100,000, patient...|(10000,[2,3,4,7,8...|[15.3258884959666...|[0.76629442479833...|       0.0|\n14 species canadi...|  1|[14, species, can...|[14, species, can...|(10000,[1,2,5,7,8...|[5.96712663310291...|[0.29835633165514...|       1.0|\n14.69 60.02 propo...|  1|[14.69, 60.02, pr...|[14.69, 60.02, pr...|(10000,[1,2,5,6,7...|[4.03148821189747...|[0.20157441059487...|       1.0|\n15 year ago opden...|  1|[15, year, ago, o...|[15, year, ago, o...|(10000,[0,1,2,6,7...|[6.44557733414162...|[0.32227886670708...|       1.0|\n1970s tomisaku ka...|  1|[1970s, tomisaku,...|[1970s, tomisaku,...|(10000,[0,2,3,4,5...|[6.92717897396851...|[0.34635894869842...|       1.0|\n1990 computer use...|  1|[1990, computer, ...|[1990, computer, ...|(10000,[0,2,6,7,8...|[7.1075313263834,...|[0.35537656631917...|       1.0|\n1992 laboratory p...|  1|[1992, laboratory...|[1992, laboratory...|(10000,[0,1,2,5,6...|[7.20195240999851...|[0.36009762049992...|       1.0|\n1995 ﻿1 pilot iss...|  0|[1995, ﻿1, pilot,...|[1995, ﻿1, pilot,...|(10000,[3,4,5,8,9...|[14.9737191261008...|[0.74868595630504...|       0.0|\n2 billion people ...|  1|[2, billion, peop...|[2, billion, peop...|(10000,[0,1,2,3,4...|[2.42822816460086...|[0.12141140823004...|       1.0|\n2 million people ...|  1|[2, million, peop...|[2, million, peop...|(10000,[0,1,2,5,7...|[6.53415859875167...|[0.32670792993758...|       1.0|\n2003 2 million ca...|  0|[2003, 2, million...|[2003, 2, million...|(10000,[1,2,5,7,8...|[16.4069184845582...|[0.82034592422791...|       0.0|\n2003 coronavirus ...|  1|[2003, coronaviru...|[2003, coronaviru...|(10000,[0,1,2,3,4...|[3.21062834196916...|[0.16053141709845...|       1.0|\n2003 hong kong pr...|  0|[2003, hong, kong...|[2003, hong, kong...|(10000,[2,3,4,7,8...|[15.3207292874978...|[0.76603646437489...|       0.0|\n2003 world strike...|  0|[2003, world, str...|[2003, world, str...|(10000,[1,2,7,8,9...|[16.6708461426496...|[0.83354230713248...|       0.0|\n2007 hiv-1 human ...|  1|[2007, hiv-1, hum...|[2007, hiv-1, hum...|(10000,[0,1,2,3,4...|[6.30864918022533...|[0.31543245901126...|       1.0|\n2008 field experi...|  1|[2008, field, exp...|[2008, field, exp...|(10000,[1,2,3,4,5...|[9.58464177642491...|[0.47923208882124...|       1.0|\n2009 h1n1 influen...|  0|[2009, h1n1, infl...|[2009, h1n1, infl...|(10000,[0,1,2,3,4...|[14.9041821293565...|[0.74520910646782...|       0.0|\n2009 infection no...|  0|[2009, infection,...|[2009, infection,...|(10000,[0,1,2,5,7...|[15.5356874828787...|[0.77678437414393...|       0.0|\n2009 pandemic inf...|  1|[2009, pandemic, ...|[2009, pandemic, ...|(10000,[0,1,2,3,4...|[2.98836085159499...|[0.14941804257974...|       1.0|\n2010 increase num...|  1|[2010, increase, ...|[2010, increase, ...|(10000,[0,1,2,5,6...|[5.51395286842580...|[0.27569764342129...|       1.0|\n+--------------------+---+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["from pyspark.sql.functions import col\nsee = predictions.select('y', col('y').alias('label'), 'rawPrediction')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"code","source":["see.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+--------------------+\n  y|label|       rawPrediction|\n+---+-----+--------------------+\n  0|    0|[15.3258884959666...|\n  1|    1|[5.96712663310291...|\n  1|    1|[4.03148821189747...|\n  1|    1|[6.44557733414162...|\n  1|    1|[6.92717897396851...|\n  1|    1|[7.1075313263834,...|\n  1|    1|[7.20195240999851...|\n  0|    0|[14.9737191261008...|\n  1|    1|[2.42822816460086...|\n  1|    1|[6.53415859875167...|\n  0|    0|[16.4069184845582...|\n  1|    1|[3.21062834196916...|\n  0|    0|[15.3207292874978...|\n  0|    0|[16.6708461426496...|\n  1|    1|[6.30864918022533...|\n  1|    1|[9.58464177642491...|\n  0|    0|[14.9041821293565...|\n  0|    0|[15.5356874828787...|\n  1|    1|[2.98836085159499...|\n  1|    1|[5.51395286842580...|\n+---+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(see, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test: Area Under ROC: 0.9852079474398303\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["# Implementing Naive Bayes Algorithm"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":40},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 23269\nTest Dataset Count: 9914\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["trainingData.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+---+--------------------+--------------------+--------------------+\n      processed_text|  y|               words|            filtered|            features|\n+--------------------+---+--------------------+--------------------+--------------------+\n1 deadline compli...|  0|[1, deadline, com...|[1, deadline, com...|(10000,[2,3,4,5,8...|\n1 introduction tr...|  1|[1, introduction,...|[1, introduction,...|(10000,[0,1,2,5,6...|\n1,4-glcnac- ␤ pre...|  1|[1,4-glcnac-, ␤, ...|[1,4-glcnac-, ␤, ...|(10000,[0,1,2,3,4...|\n10 case 23.81 urt...|  0|[10, case, 23.81,...|[10, case, 23.81,...|(10000,[1,2,3,4,5...|\n114 catalytic hyd...|  1|[114, catalytic, ...|[114, catalytic, ...|(10000,[0,1,2,5,6...|\n120 year pass wal...|  1|[120, year, pass,...|[120, year, pass,...|(10000,[0,1,2,3,4...|\n17 160 type modif...|  1|[17, 160, type, m...|[17, 160, type, m...|(10000,[0,2,3,4,6...|\n170 million chron...|  0|[170, million, ch...|[170, million, ch...|(10000,[0,1,2,5,7...|\n170 million peopl...|  1|[170, million, pe...|[170, million, pe...|(10000,[0,1,2,5,6...|\n1918 world war wi...|  0|[1918, world, war...|[1918, world, war...|(10000,[1,2,3,4,5...|\n1959 richard feyn...|  1|[1959, richard, f...|[1959, richard, f...|(10000,[0,1,2,3,4...|\n1980 average new ...|  0|[1980, average, n...|[1980, average, n...|(10000,[1,2,5,6,7...|\n1980s world healt...|  0|[1980s, world, he...|[1980s, world, he...|(10000,[1,2,5,6,7...|\n1995 haemophilus ...|  1|[1995, haemophilu...|[1995, haemophilu...|(10000,[0,1,2,7,8...|\n1997 highly patho...|  1|[1997, highly, pa...|[1997, highly, pa...|(10000,[0,1,2,3,4...|\n1997 study report...|  1|[1997, study, rep...|[1997, study, rep...|(10000,[0,1,2,3,4...|\n1998 world health...|  0|[1998, world, hea...|[1998, world, hea...|(10000,[2,5,7,8,9...|\n20 year alphaviru...|  1|[20, year, alphav...|[20, year, alphav...|(10000,[0,1,2,3,4...|\n200 different typ...|  1|[200, different, ...|[200, different, ...|(10000,[0,1,2,3,4...|\n2000-year medicin...|  1|[2000-year, medic...|[2000-year, medic...|(10000,[0,1,2,3,4...|\n+--------------------+---+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["from pyspark.ml.classification import NaiveBayes\n\n# create the trainer and set its parameters\nnb = NaiveBayes(labelCol=\"y\", smoothing=1, modelType=\"multinomial\")\n\n# train the model\nmodel = nb.fit(trainingData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":43},{"cell_type":"code","source":["predictions = model.transform(testData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":44},{"cell_type":"code","source":["from pyspark.sql.functions import col\nsee = predictions.select('y', col('y').alias('label'), 'rawPrediction')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":45},{"cell_type":"code","source":["see.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+--------------------+\n  y|label|       rawPrediction|\n+---+-----+--------------------+\n  0|    0|[-18666.460436596...|\n  1|    1|[-22603.981148977...|\n  1|    1|[-22899.388092472...|\n  1|    1|[-25924.598706984...|\n  1|    1|[-17133.734486037...|\n  1|    1|[-14173.444250163...|\n  1|    1|[-9184.8233511717...|\n  0|    0|[-2873.8723871638...|\n  1|    1|[-27673.176842173...|\n  1|    1|[-19191.953094462...|\n  0|    0|[-24145.664466697...|\n  1|    1|[-26097.160151904...|\n  0|    0|[-15426.634830047...|\n  0|    0|[-21017.088992637...|\n  1|    1|[-17604.991833846...|\n  1|    1|[-21349.718743404...|\n  0|    0|[-15794.014598697...|\n  0|    0|[-7266.3274231718...|\n  1|    1|[-20257.909321387...|\n  1|    1|[-24089.690589153...|\n+---+-----+--------------------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":46},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(see, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test: Area Under ROC: 0.38929004266271305\n</div>"]}}],"execution_count":47},{"cell_type":"code","source":["# Implementing cross validation"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":48},{"cell_type":"code","source":["(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\nprint(\"Test Dataset Count: \" + str(testData.count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training Dataset Count: 23269\nTest Dataset Count: 9914\n</div>"]}}],"execution_count":49},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nlr = LogisticRegression(labelCol=\"y\", maxIter=20, regParam=0.3, elasticNetParam=0, family = \"binomial\")\n# lr = LogisticRegression()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["from pyspark.sql.functions import col\nupdatedTrainingData = trainingData.select('y', col('y').alias('label'), 'features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":51},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n             .build())\n\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, \\\n                    estimatorParamMaps=paramGrid, \\\n                    evaluator=evaluator, \\\n                    numFolds=3)\n\n# Run cross validations\ncvModel = cv.fit(updatedTrainingData)\n# this will likely take a fair amount of time because of the amount of models that we're creating and testing"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":52},{"cell_type":"code","source":["from pyspark.sql.functions import col\nupdatedTestData = testData.select('y', col('y').alias('label'), 'features')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":53},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(updatedTestData)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":54},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Test: Area Under ROC: 0.9956686209314644\n</div>"]}}],"execution_count":55},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[109]: 0.9956686209314627</div>"]}}],"execution_count":56},{"cell_type":"code","source":["predictions.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+--------------------+--------------------+--------------------+----------+\n  y|label|            features|       rawPrediction|         probability|prediction|\n+---+-----+--------------------+--------------------+--------------------+----------+\n  0|    0|(10000,[2,3,4,7,8...|[8.02256287819271...|[0.99967212915841...|       0.0|\n  1|    1|(10000,[1,2,5,7,8...|[-4.8676098316721...|[0.00763301677090...|       1.0|\n  1|    1|(10000,[1,2,5,6,7...|[-6.9189511334220...|[9.87889694787093...|       1.0|\n  1|    1|(10000,[0,1,2,6,7...|[-5.9910607788866...|[0.00249477018013...|       1.0|\n  1|    1|(10000,[0,2,3,4,5...|[-1.6245902541570...|[0.16457279053114...|       1.0|\n  1|    1|(10000,[0,2,6,7,8...|[-3.0891965829182...|[0.04355509146977...|       1.0|\n  1|    1|(10000,[0,1,2,5,6...|[-1.0486892781689...|[0.25947687480704...|       1.0|\n  0|    0|(10000,[3,4,5,8,9...|[1.69920859487066...|[0.84543134459088...|       0.0|\n  1|    1|(10000,[0,1,2,3,4...|[-8.4287966324691...|[2.18436524172421...|       1.0|\n  1|    1|(10000,[0,1,2,5,7...|[-3.0981930889562...|[0.04318184981257...|       1.0|\n  0|    0|(10000,[1,2,5,7,8...|[10.6581510023021...|[0.99997649211145...|       0.0|\n  1|    1|(10000,[0,1,2,3,4...|[-5.4401085591703...|[0.00432026651645...|       1.0|\n  0|    0|(10000,[2,3,4,7,8...|[5.67047749554621...|[0.99656561631066...|       0.0|\n  0|    0|(10000,[1,2,7,8,9...|[9.11526744241215...|[0.99989003818736...|       0.0|\n  1|    1|(10000,[0,1,2,3,4...|[-6.9487283032745...|[9.58934584190184...|       1.0|\n  1|    1|(10000,[1,2,3,4,5...|[-3.9395888625760...|[0.01908489255732...|       1.0|\n  0|    0|(10000,[0,1,2,3,4...|[6.20364835789404...|[0.99798204035820...|       0.0|\n  0|    0|(10000,[0,1,2,5,7...|[4.00871533890843...|[0.98216708157381...|       0.0|\n  1|    1|(10000,[0,1,2,3,4...|[-5.8360252895251...|[0.00291192338001...|       1.0|\n  1|    1|(10000,[0,1,2,5,6...|[-5.7692602385461...|[0.00311234928372...|       1.0|\n+---+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n</div>"]}}],"execution_count":57},{"cell_type":"code","source":["from pyspark.sql.functions import col\nupdatedPredictions = predictions.select('prediction', col('prediction').alias('ctx'), 'label')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58}],"metadata":{"name":"CIS5560projectFinal","notebookId":1094106094674987},"nbformat":4,"nbformat_minor":0}
